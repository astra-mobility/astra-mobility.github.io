"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[768],{72193:(e,t,r)=>{r.r(t),r.d(t,{default:()=>se});var n=r(52983),i=function(){if("undefined"!=typeof Map)return Map;function e(e,t){var r=-1;return e.some((function(e,n){return e[0]===t&&(r=n,!0)})),r}return function(){function t(){this.__entries__=[]}return Object.defineProperty(t.prototype,"size",{get:function(){return this.__entries__.length},enumerable:!0,configurable:!0}),t.prototype.get=function(t){var r=e(this.__entries__,t),n=this.__entries__[r];return n&&n[1]},t.prototype.set=function(t,r){var n=e(this.__entries__,t);~n?this.__entries__[n][1]=r:this.__entries__.push([t,r])},t.prototype.delete=function(t){var r=this.__entries__,n=e(r,t);~n&&r.splice(n,1)},t.prototype.has=function(t){return!!~e(this.__entries__,t)},t.prototype.clear=function(){this.__entries__.splice(0)},t.prototype.forEach=function(e,t){void 0===t&&(t=null);for(var r=0,n=this.__entries__;r<n.length;r++){var i=n[r];e.call(t,i[1],i[0])}},t}()}(),o="undefined"!=typeof window&&"undefined"!=typeof document&&window.document===document,a=void 0!==r.g&&r.g.Math===Math?r.g:"undefined"!=typeof self&&self.Math===Math?self:"undefined"!=typeof window&&window.Math===Math?window:Function("return this")(),s="function"==typeof requestAnimationFrame?requestAnimationFrame.bind(a):function(e){return setTimeout((function(){return e(Date.now())}),1e3/60)};var l=["top","right","bottom","left","width","height","size","weight"],c="undefined"!=typeof MutationObserver,d=function(){function e(){this.connected_=!1,this.mutationEventsAdded_=!1,this.mutationsObserver_=null,this.observers_=[],this.onTransitionEnd_=this.onTransitionEnd_.bind(this),this.refresh=function(e,t){var r=!1,n=!1,i=0;function o(){r&&(r=!1,e()),n&&l()}function a(){s(o)}function l(){var e=Date.now();if(r){if(e-i<2)return;n=!0}else r=!0,n=!1,setTimeout(a,t);i=e}return l}(this.refresh.bind(this),20)}return e.prototype.addObserver=function(e){~this.observers_.indexOf(e)||this.observers_.push(e),this.connected_||this.connect_()},e.prototype.removeObserver=function(e){var t=this.observers_,r=t.indexOf(e);~r&&t.splice(r,1),!t.length&&this.connected_&&this.disconnect_()},e.prototype.refresh=function(){this.updateObservers_()&&this.refresh()},e.prototype.updateObservers_=function(){var e=this.observers_.filter((function(e){return e.gatherActive(),e.hasActive()}));return e.forEach((function(e){return e.broadcastActive()})),e.length>0},e.prototype.connect_=function(){o&&!this.connected_&&(document.addEventListener("transitionend",this.onTransitionEnd_),window.addEventListener("resize",this.refresh),c?(this.mutationsObserver_=new MutationObserver(this.refresh),this.mutationsObserver_.observe(document,{attributes:!0,childList:!0,characterData:!0,subtree:!0})):(document.addEventListener("DOMSubtreeModified",this.refresh),this.mutationEventsAdded_=!0),this.connected_=!0)},e.prototype.disconnect_=function(){o&&this.connected_&&(document.removeEventListener("transitionend",this.onTransitionEnd_),window.removeEventListener("resize",this.refresh),this.mutationsObserver_&&this.mutationsObserver_.disconnect(),this.mutationEventsAdded_&&document.removeEventListener("DOMSubtreeModified",this.refresh),this.mutationsObserver_=null,this.mutationEventsAdded_=!1,this.connected_=!1)},e.prototype.onTransitionEnd_=function(e){var t=e.propertyName,r=void 0===t?"":t;l.some((function(e){return!!~r.indexOf(e)}))&&this.refresh()},e.getInstance=function(){return this.instance_||(this.instance_=new e),this.instance_},e.instance_=null,e}(),u=function(e,t){for(var r=0,n=Object.keys(t);r<n.length;r++){var i=n[r];Object.defineProperty(e,i,{value:t[i],enumerable:!1,writable:!1,configurable:!0})}return e},h=function(e){return e&&e.ownerDocument&&e.ownerDocument.defaultView||a},m=w(0,0,0,0);function f(e){return parseFloat(e)||0}function p(e){for(var t=[],r=1;r<arguments.length;r++)t[r-1]=arguments[r];return t.reduce((function(t,r){return t+f(e["border-"+r+"-width"])}),0)}function b(e){var t=e.clientWidth,r=e.clientHeight;if(!t&&!r)return m;var n=h(e).getComputedStyle(e),i=function(e){for(var t={},r=0,n=["top","right","bottom","left"];r<n.length;r++){var i=n[r],o=e["padding-"+i];t[i]=f(o)}return t}(n),o=i.left+i.right,a=i.top+i.bottom,s=f(n.width),l=f(n.height);if("border-box"===n.boxSizing&&(Math.round(s+o)!==t&&(s-=p(n,"left","right")+o),Math.round(l+a)!==r&&(l-=p(n,"top","bottom")+a)),!function(e){return e===h(e).document.documentElement}(e)){var c=Math.round(s+o)-t,d=Math.round(l+a)-r;1!==Math.abs(c)&&(s-=c),1!==Math.abs(d)&&(l-=d)}return w(i.left,i.top,s,l)}var v="undefined"!=typeof SVGGraphicsElement?function(e){return e instanceof h(e).SVGGraphicsElement}:function(e){return e instanceof h(e).SVGElement&&"function"==typeof e.getBBox};function g(e){return o?v(e)?function(e){var t=e.getBBox();return w(0,0,t.width,t.height)}(e):b(e):m}function w(e,t,r,n){return{x:e,y:t,width:r,height:n}}var x=function(){function e(e){this.broadcastWidth=0,this.broadcastHeight=0,this.contentRect_=w(0,0,0,0),this.target=e}return e.prototype.isActive=function(){var e=g(this.target);return this.contentRect_=e,e.width!==this.broadcastWidth||e.height!==this.broadcastHeight},e.prototype.broadcastRect=function(){var e=this.contentRect_;return this.broadcastWidth=e.width,this.broadcastHeight=e.height,e},e}(),y=function(e,t){var r,n,i,o,a,s,l,c=(n=(r=t).x,i=r.y,o=r.width,a=r.height,s="undefined"!=typeof DOMRectReadOnly?DOMRectReadOnly:Object,l=Object.create(s.prototype),u(l,{x:n,y:i,width:o,height:a,top:i,right:n+o,bottom:a+i,left:n}),l);u(this,{target:e,contentRect:c})},_=function(){function e(e,t,r){if(this.activeObservations_=[],this.observations_=new i,"function"!=typeof e)throw new TypeError("The callback provided as parameter 1 is not a function.");this.callback_=e,this.controller_=t,this.callbackCtx_=r}return e.prototype.observe=function(e){if(!arguments.length)throw new TypeError("1 argument required, but only 0 present.");if("undefined"!=typeof Element&&Element instanceof Object){if(!(e instanceof h(e).Element))throw new TypeError('parameter 1 is not of type "Element".');var t=this.observations_;t.has(e)||(t.set(e,new x(e)),this.controller_.addObserver(this),this.controller_.refresh())}},e.prototype.unobserve=function(e){if(!arguments.length)throw new TypeError("1 argument required, but only 0 present.");if("undefined"!=typeof Element&&Element instanceof Object){if(!(e instanceof h(e).Element))throw new TypeError('parameter 1 is not of type "Element".');var t=this.observations_;t.has(e)&&(t.delete(e),t.size||this.controller_.removeObserver(this))}},e.prototype.disconnect=function(){this.clearActive(),this.observations_.clear(),this.controller_.removeObserver(this)},e.prototype.gatherActive=function(){var e=this;this.clearActive(),this.observations_.forEach((function(t){t.isActive()&&e.activeObservations_.push(t)}))},e.prototype.broadcastActive=function(){if(this.hasActive()){var e=this.callbackCtx_,t=this.activeObservations_.map((function(e){return new y(e.target,e.broadcastRect())}));this.callback_.call(e,t,e),this.clearActive()}},e.prototype.clearActive=function(){this.activeObservations_.splice(0)},e.prototype.hasActive=function(){return this.activeObservations_.length>0},e}(),j="undefined"!=typeof WeakMap?new WeakMap:new i,C=function e(t){if(!(this instanceof e))throw new TypeError("Cannot call a class as a function.");if(!arguments.length)throw new TypeError("1 argument required, but only 0 present.");var r=d.getInstance(),n=new _(t,r,this);j.set(this,n)};["observe","unobserve","disconnect"].forEach((function(e){C.prototype[e]=function(){var t;return(t=j.get(this))[e].apply(t,arguments)}}));var M=void 0!==a.ResizeObserver?a.ResizeObserver:C,A=function(e,t){var r=(0,n.useRef)(!1);(0,n.useEffect)((function(){return r.current?e():(r.current=!0,function(){})}),t)};function E(e){return function(e){if(Array.isArray(e))return k(e)}(e)||function(e){if("undefined"!=typeof Symbol&&Symbol.iterator in Object(e))return Array.from(e)}(e)||function(e,t){if(!e)return;if("string"==typeof e)return k(e,t);var r=Object.prototype.toString.call(e).slice(8,-1);"Object"===r&&e.constructor&&(r=e.constructor.name);if("Map"===r||"Set"===r)return Array.from(e);if("Arguments"===r||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(r))return k(e,t)}(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}function k(e,t){(null==t||t>e.length)&&(t=e.length);for(var r=0,n=new Array(t);r<t;r++)n[r]=e[r];return n}var O=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:1e3,r=arguments.length>2&&void 0!==arguments[2]?arguments[2]:[],i=arguments.length>3&&void 0!==arguments[3]?arguments[3]:{},o=i.immediately,a=void 0!==o&&o,s=i.trailing,l=void 0===s||s,c=i.leading,d=void 0!==c&&c,u=r,h=t,m=(0,n.useRef)(),f=(0,n.useRef)(!1),p=(0,n.useRef)(e);p.current=e;var b=(0,n.useRef)([]),v=(0,n.useCallback)((function(){m.current&&clearTimeout(m.current),m.current=void 0}),[]),g=(0,n.useCallback)((function(){for(var e=arguments.length,t=new Array(e),r=0;r<e;r++)t[r]=arguments[r];if(b.current=t,!m.current){if(a&&!f.current)return p.current.apply(p,E(b.current)),void(f.current=!0);d&&p.current.apply(p,E(b.current)),m.current=function(e){return window.setTimeout((function(){e&&p.current.apply(p,E(b.current)),m.current=void 0,f.current=!1}),h)}(l)}}),[h,v]);return A((function(){g()}),[].concat(E(u),[g])),(0,n.useEffect)((function(){return v}),[]),{run:g,cancel:v}};function S(e){return function(e){if(Array.isArray(e))return z(e)}(e)||function(e){if("undefined"!=typeof Symbol&&Symbol.iterator in Object(e))return Array.from(e)}(e)||N(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}function L(e,t){return function(e){if(Array.isArray(e))return e}(e)||function(e,t){if("undefined"==typeof Symbol||!(Symbol.iterator in Object(e)))return;var r=[],n=!0,i=!1,o=void 0;try{for(var a,s=e[Symbol.iterator]();!(n=(a=s.next()).done)&&(r.push(a.value),!t||r.length!==t);n=!0);}catch(l){i=!0,o=l}finally{try{n||null==s.return||s.return()}finally{if(i)throw o}}return r}(e,t)||N(e,t)||function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}function N(e,t){if(e){if("string"==typeof e)return z(e,t);var r=Object.prototype.toString.call(e).slice(8,-1);return"Object"===r&&e.constructor&&(r=e.constructor.name),"Map"===r||"Set"===r?Array.from(e):"Arguments"===r||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(r)?z(e,t):void 0}}function z(e,t){(null==t||t>e.length)&&(t=e.length);for(var r=0,n=new Array(t);r<t;r++)n[r]=e[r];return n}var T=function(e){var t,r,i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},o=arguments.length>2&&void 0!==arguments[2]?arguments[2]:[],a=50;"string"==typeof i?t=i:(i.dimension&&(t=i.dimension),i.throttle&&(a=i.throttle),i.throttleOption&&(r=i.throttleOption));var s=(0,n.useRef)(),l=L((0,n.useState)((function(){var t="function"==typeof e?e():e;return{width:(t||{}).clientWidth||0,height:(t||{}).clientHeight||0}})),2),c=l[0],d=l[1],u=(0,n.useCallback)((function(e){if(null!=e&&e.length){var r=e[0].contentRect,n=r.width,i=r.height;d((function(e){return e?"width"===t?e.width!==n?{width:n,height:i}:e:"height"===t?e.height!==i?{width:n,height:i}:e:e.width!==n||e.height!==i?{width:n,height:i}:e:{width:n,height:i}}))}}),[t]),h=O(u,a,[u],r).run;return(0,n.useLayoutEffect)((function(){var t=s.current;e&&(t="function"==typeof e?e():e);var r=new M(h);return t&&r.observe(t),function(){return r.disconnect()}}),[s.current,"function"==typeof e?void 0:e,u].concat(S(o))),[s,c]},D=r(80541),H=r.p+"static/image/astra_framework.500b1ef1.png",R=r.p+"static/image/astra_global.667348e7.png",F=r.p+"static/image/astra_local.536fd477.png",V=r.p+"static/image/multimodal_query.64f02b25.png",G=r.p+"static/image/reloc_acc_compare_vpr.96006e5b.jpg",I=r.p+"static/image/seq1_traj.94a0c913.png",q=r.p+"static/image/seq2_traj.8332976d.png",W=r.p+"static/image/seq3_traj.0cb76c2a.png",P=r.p+"static/image/esdf_loss.694d0839.jpg",B=r.p+"static/image/planning_radar.f10cc17a.jpg",U=r(98692),X=r(6480),K=r(93901),Q=r(97458);const Z=["children"],Y={paper:(0,Q.jsx)("svg",{"aria-hidden":"true","data-fa-i2svg":"","data-icon":"file-pdf","data-prefix":"fas",focusable:"false",height:22,role:"img",viewBox:"0 0 512 512",width:22,xmlns:"http://www.w3.org/2000/svg",children:(0,Q.jsx)("path",{d:"M0 64C0 28.7 28.7 0 64 0H224V128c0 17.7 14.3 32 32 32H384V304H176c-35.3 0-64 28.7-64 64V512H64c-35.3 0-64-28.7-64-64V64zm384 64H256V0L384 128zM176 352h32c30.9 0 56 25.1 56 56s-25.1 56-56 56H192v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V448 368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24H192v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48H304c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16V400c0-8.8-7.2-16-16-16H320v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16H448v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16H448v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V432 368z",fill:"currentColor"})}),youtube:(0,Q.jsx)("svg",{"aria-hidden":"true","data-fa-i2svg":"","data-icon":"youtube","data-prefix":"fab",focusable:"false",height:22,role:"img",viewBox:"0 0 576 512",width:22,xmlns:"http://www.w3.org/2000/svg",children:(0,Q.jsx)("path",{d:"M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z",fill:"currentColor"})}),bilibili:(0,Q.jsx)("svg",{"aria-hidden":"true","data-fa-i2svg":"","data-icon":"bilibili","data-prefix":"fab",focusable:"false",height:22,role:"img",viewBox:"0 0 512 512",width:22,xmlns:"http://www.w3.org/2000/svg",children:(0,Q.jsx)("path",{d:"M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92.02C65.57 463.2 43.81 454.2 26.74 436.8C9.682 419.4 .7667 396.5 0 368.2V169.8C.7667 143.8 9.682 122.2 26.74 104.1C43.81 87.75 65.57 78.77 92.02 78H121.4L96.05 52.19C90.3 46.46 87.42 39.19 87.42 30.4C87.42 21.6 90.3 14.34 96.05 8.603C101.8 2.868 109.1 0 117.9 0C126.7 0 134 2.868 139.8 8.603L213.1 78H301.1L375.6 8.603C381.7 2.868 389.2 0 398 0C406.8 0 414.1 2.868 419.9 8.603C425.6 14.34 428.5 21.6 428.5 30.4C428.5 39.19 425.6 46.46 419.9 52.19L394.6 78L423.9 78C450.3 78.77 471.9 87.75 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.05C86.46 140.9 78.6 144.2 72.47 150.3C66.33 156.4 63.07 164.2 62.69 173.8V368.2C62.69 377.4 65.95 385.2 72.47 391.7C78.99 398.2 86.85 401.5 96.05 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z",fill:"currentColor"})}),cite:(0,Q.jsx)("svg",{"aria-hidden":"true","data-fa-i2svg":"","data-icon":"quote-left","data-prefix":"fas",focusable:"false",height:22,role:"img",viewBox:"0 0 448 512",width:22,xmlns:"http://www.w3.org/2000/svg",children:(0,Q.jsx)("path",{d:"M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V320 288 216zm256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H320c-35.3 0-64-28.7-64-64V320 288 216z",fill:"currentColor"})})},$=e=>{const{children:t}=e,r=(0,K.Z)(e,Z);return(0,Q.jsx)("div",(0,X.Z)((0,X.Z)({},r),{},{className:" flex h-10 items-center justify-center gap-2 rounded-[20px] border-[1px] border-[#DDE2E9] bg-white px-6 text-[16px] font-semibold leading-[28px] text-[#42464E] shadow-[0px_1px_1px_0px_#DDE2E9] transition ease-in-out hover:translate-y-[-1px] hover:cursor-pointer ",children:t}))},J=()=>{const e=(0,U.d)();return(0,Q.jsxs)("div",{className:(0,D.m)(e?"grid gap-4 grid-cols-2 grid-rows-2 mb-6":"flex flex-wrap justify-center gap-3 mb-[60px]"),children:[(0,Q.jsxs)($,{onClick:()=>{window.open("https://arxiv.org/pdf/2506.06205","_blank")},children:[Y.paper," ",(0,Q.jsx)("span",{children:"Paper"})]}),(0,Q.jsxs)($,{onClick:()=>{window.open("https://www.youtube.com/watch?v=X0-FuMO4GKo","_blank")},children:[Y.youtube," ",(0,Q.jsx)("span",{children:"YouTube"})]})]})};var ee={wrapper:"wrapper-IaQ7iE",header:"header-WWbz6K","header-mobile":"header-mobile-FfIX0R",headerMobile:"header-mobile-FfIX0R",subtitle:"subtitle-j95RCE",abstract:"abstract-CX4spt","abstract-mobile":"abstract-mobile-EzVQ0x",abstractMobile:"abstract-mobile-EzVQ0x",text:"text-VpKXVg","text-mobile":"text-mobile-BCFUaM",textMobile:"text-mobile-BCFUaM",title:"title-exvvTv","title-mobile":"title-mobile-sDKMOP",titleMobile:"title-mobile-sDKMOP",layout:"layout-W8rEGd","mobile-layout":"mobile-layout-HoPqbR",mobileLayout:"mobile-layout-HoPqbR"};const te=[[r.p+"static/media/0001.ba445ee3.mp4",r.p+"static/media/0002.0fa93575.mp4"],[r.p+"static/media/0003.cf01fbc0.mp4",r.p+"static/media/0004.9caee1e6.mp4"],[r.p+"static/media/0005.8a8ade31.mp4",r.p+"static/media/0006.00042c3e.mp4"],[r.p+"static/media/0007.d3cbac1c.mp4",r.p+"static/media/0008.12791219.mp4"],[r.p+"static/media/0009.701ab471.mp4",r.p+"static/media/0010.40c37a73.mp4"]],re=({videoSrc:e,className:t=""})=>{const r=(0,n.useRef)(null),i=e=>{const[t]=e;t&&t.isIntersecting&&o()};(0,n.useEffect)((()=>{const e=new IntersectionObserver(i,{root:null,rootMargin:"0px",threshold:.1});return r.current&&e.observe(r.current),()=>{r.current&&e.unobserve(r.current)}}),[]);const o=()=>{const t=r.current;t&&!t.src&&(t.src=e,t.load(),t.play())};return(0,Q.jsx)("video",{ref:r,className:"w-full rounded-md",controlsList:"nodownload",loop:!0,muted:!0})};const ne=te.map((e=>function(e){for(let t=e.length-1;t>0;t--){const r=Math.floor(Math.random()*(t+1)),n=e[t];e[t]=e[r],e[r]=n}return e}(e))),ie=()=>{var e,t;const r=(0,U.d)(),[i,o]=(0,n.useState)(0);console.log("Video data:",{videos:te,activeIndex:i,currentVideos:ne[i],isMobile:r});return(0,Q.jsxs)("div",{className:(0,D.m)("flex w-full flex-col",r?"gap-6":"gap-10"),children:[(0,Q.jsx)("div",{className:"flex justify-center",children:(0,Q.jsx)("button",{className:(0,D.m)("flex items-center justify-center rounded-md bg-[#0C0D0E] px-6 font-semibold  text-white transition ease-in-out hover:translate-y-[-1px] hover:cursor-pointer",r?"h-[40px] text-[16px] leading-[24px]":"h-[50px] text-[20px] leading-[28px]"),onClick:()=>{o((e=>e===te.length-1?0:e+1))},type:"button",children:"Click to View More"})}),(0,Q.jsx)("div",{className:(0,D.m)("rounded-2xl",r?"w-full grid grid-cols-1 grid-rows-1 gap-2":"grid w-full grid-cols-2 grid-rows-1 gap-2"),children:r?null===(e=ne[i])||void 0===e||null===(e=e.slice(0,4))||void 0===e?void 0:e.map((e=>(0,Q.jsx)(re,{videoSrc:e},e))):null===(t=ne[i])||void 0===t?void 0:t.map((e=>(0,Q.jsx)(re,{videoSrc:e},e)))})]})},oe=(0,n.forwardRef)((({title:e="",children:t,className:r,style:n},i)=>{const o=(0,U.d)();return(0,Q.jsxs)("div",{ref:i,className:(0,D.m)(ee[o?"mobile-layout":"layout"],o?"mb-8":"mb-[80px]",r),style:n,children:[e&&(0,Q.jsx)("div",{className:(0,D.m)(o?ee["title-mobile"]:ee.title),children:e}),t]})})),ae=({imgSrc:e,className:t="",subtitle:r})=>{const n=(0,U.d)();return(0,Q.jsxs)("div",{className:(0,D.m)("w-full flex flex-col items-center gap-2",t),children:[(0,Q.jsx)("img",{className:"w-[90%]",src:e}),Boolean(r)&&(0,Q.jsx)("div",{className:(0,D.m)("text-center font-[150] leading-[24px] text-[#1D2129]",n?"text-[15px]":"text-[18px]"),children:r})]})};var se=()=>{const e=(0,U.d)(),[t,{width:r}]=T();return(0,n.useEffect)((()=>{document.addEventListener("contextmenu",(function(e){e.preventDefault()}))}),[]),(0,Q.jsxs)("div",{className:(0,D.m)("flex w-full flex-col bg-white font-[lato] items-center",ee.wrapper,e?"px-8":""),children:[(0,Q.jsx)("div",{className:(0,D.m)(ee[e?"header-mobile":"header"],e?"my-5":"my-8"),children:"Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning"}),(0,Q.jsx)("div",{className:(0,D.m)(ee.subtitle,ee[e?"mobile-layout":"layout"],e?"mb-[30px]":"mb-[60px]"),children:"Bytedance Seed"}),(0,Q.jsx)(J,{}),(0,Q.jsx)("div",{className:(0,D.m)(e?ee["abstract-mobile"]:ee.abstract,e?"w-full mb-[20px]":"w-[65%] mb-[80px]"),children:"Modern robot navigation systems encounter difficulties in diverse and complex indoor environments. Traditional approaches rely on multiple modules with small models or rule-based systems and thus lack adaptability to new environments. To address this, we developed Astra, a comprehensive dual-model architecture, Astra-Global and Astra-Local, for mobile robot navigation. Astra-Global, a multimodal LLM, processes vision and language inputs to perform self and goal localization using a hybrid topological-semantic graph as the global map, and outperforms traditional visual place recognition methods. Astra-Local, a multitask network, handles local path planning and odometry estimation. Its 4D spatial-temporal encoder, trained through self-supervised learning, generates robust 4D features for downstream tasks. The planning head utilizes flow matching and a novel masked ESDF loss to minimize collision risks for generating local trajectories, and the odometry head integrates multi-sensor inputs via a transformer encoder to predict the relative pose of the robot. Deployed on real in-house mobile robots, Astra achieves high end-to-end mission success rate across diverse indoor environments."}),(0,Q.jsx)(oe,{ref:t,children:(0,Q.jsx)("iframe",{allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",height:r/16*9,referrerPolicy:"strict-origin-when-cross-origin",src:"https://www.youtube.com/embed/X0-FuMO4GKo?si=16PnA1KqSdsWO6s_",title:"YouTube video player",width:r})}),(0,Q.jsx)(oe,{title:"Astra Overview",children:(0,Q.jsx)("div",{className:"flex flex-row justify-center w-full",children:(0,Q.jsx)(ae,{className:e?"mt-[20px]":"mt-[50px] w-[100%]",imgSrc:H,subtitle:"Figure 1: Astra Overview. Astra addresses three key navigation problems: goal localization, self localization, and path planning, with the help of Astra-Global and Astra-Local. Astra-Global is responsible for goal and self localization. In the case of goal localization, it locates the landmark and the corresponding goal pose from the map based on user text prompts. For self localization, Astra-Global identifies visual landmarks from images robot perceives and integrates this information with the odometry estimated by Astra-Local through multi-sensor fusion to obtain the robot's global pose. Meanwhile, Astra-Local takes an additional subgoal as input for path planning and generates a local path for the robot to follow."})})}),(0,Q.jsxs)(oe,{title:"Astra-Global",children:[(0,Q.jsx)("div",{className:e?ee["text-mobile"]:ee.text,children:"Astra-Global is a multimodal LLM (MLLM) that is responsible for self and goal localization within a global map. We represent the known environment as a topological-semantic map that can be directly taken as contexture input to a MLLM. Given this map representation, and a query image or text prompt, the model locates the query within the map. The query can be a text prompt from a user, e.g. \"I'd like to find somewhere to rest\", in which case the model locates the goal in the map. When the query is an image the robot currently perceives, the model locates the robot instead. Unlike traditional global localization methods for mobile robots that typically relies on some sorts of artificial landmarks like QR-codes or additional sensors for complex scenes, Astra-Global utilizes natural landmarks built for humans and works for diverse environment. We train Astra-Global using Supervised Finetuning (SFT) and Reinforcement Learning (RL). Astra-Global outperforms traditional Visual Place Recognition (VPR) methods across all environments and works zero-shot in new environments. Our experiments demonstrate that RL is an effective approach for enhancing the model's generalization capabilities and is more data efficient than using SFT alone."}),(0,Q.jsx)("div",{className:"flex flex-row justify-center w-full",children:(0,Q.jsx)(ae,{className:e?"mt-[20px]":"mt-[50px] w-[65%]",imgSrc:R,subtitle:"Figure 2: Astra-Global follows most modern MLLMs where images are encoded via a separate visual encoder and further aligned with text tokens with a projector. Map is represented as a combination of images and texts depending on localization stage. The encoded vision tokens and text tokens are fed into a LLM to generate the final results."})}),(0,Q.jsxs)("div",{className:"flex flex-row justify-between w-full",children:[(0,Q.jsx)(ae,{imgSrc:V,className:e?"mt-[20px] w-[45%]":"mt-[50px] w-[45%]",subtitle:"Figure 3: Astra-Global can handle multi-modal localization queries."}),(0,Q.jsx)(ae,{imgSrc:G,className:e?"mt-[20px] w-[45%]":"mt-[50px]",subtitle:"Figure 4: Astra-Global can handle diverse indoor environments."})]})]}),(0,Q.jsxs)(oe,{title:"Astra Local",children:[(0,Q.jsx)("div",{className:e?ee["text-mobile"]:ee.text,children:"Astra-Local is a multi-task network that generates local path and estimates odometry from sensor data in an end-to-end fashion. The architecture for Astra-Local is shown in Fig. 5. The model consists of three components: a 4D Spatial-Temporal encoder that processes multi-frame, multi-camera inputs to generate a 4D feature that's aligned with real-world coordinates, serving as input for downstream tasks; a Planning Head and a Odometry Head that both take 4D features from the encoder together with additional inputs to generate executable trajectories for robot to follow and estimates relative pose between current frame and previous frames."}),(0,Q.jsx)(ae,{className:e?"mt-[20px]":"mt-[50px]",imgSrc:F,subtitle:"Figure 5: Astra-Local architecture."})]}),(0,Q.jsxs)(oe,{title:"4D Spatial-Temporal Encoder",children:[(0,Q.jsx)("div",{className:e?ee["text-mobile"]:ee.text,children:"In traditional mobility stack, perception and prediction modules serve as critical components by enabling agents to fuse information from the past and acquire both current and future environmental states. In Astra-Local, we propose a unified 4D spatial-temporal encoder to supplant the two distinct modules. The 3D spatial encoder is trained at first to generate common representations through vast amounts of unlabeled data via a self-supervised learning paradigm. Then, the 4D spatial-temporal encoder is trained to forecast future environmental representations on top of the 3D encoder. Pretrained on large scale datasets in a self-supervised manner, our 4D Spatial-Temporal Encoder provides robust spatial-temporal visual features for downstream tasks."}),(0,Q.jsx)("div",{className:(0,D.m)(e?"w-[100%] mb-10":"w-[100%] mb-[100px]"),children:(0,Q.jsx)(ie,{})})]}),(0,Q.jsx)(oe,{title:"Planning Head",children:(0,Q.jsx)("div",{className:e?ee["text-mobile"]:ee.text,children:"Our planning head takes the pretrained 4D features as condition, along with robot velocity and task information like goal pose, reconstructs an action trajectory from a Gaussian noise with flow matching. We propose a novel masked ESDF loss that can drastically reduce the collision rate for various planning head implementations. When combined with flow matching, we achive the best results in terms of collision rate, velocity and a trajectory scoring function."})}),(0,Q.jsxs)("div",{className:"flex flex-row justify-center w-full",children:[(0,Q.jsx)(ae,{imgSrc:P,className:e?"mt-[20px] w-[45%]":"mt-[50px] w-[35%]",subtitle:"Figure 6a: Effectiveness of ESDF loss for various policy heads"}),(0,Q.jsx)(ae,{imgSrc:B,className:e?"mt-[20px] w-[45%]":"mt-[50px] w-[35%]",subtitle:"Figure 6b: Comparison of different policy heads"})]}),(0,Q.jsxs)(oe,{title:"Odometry Head",children:[(0,Q.jsx)("div",{className:e?ee["text-mobile"]:ee.text,children:"The odometry head predicts relative robot pose given current and past 4D features from the 4D encoder and additional sensor including IMU, wheel. We train a transformer model to fuse information from different sensors. For each time step, each modality (4D vision feature, IMU, wheel) goes through a modality-specific tokenizer to get tokens for that time step. Combined with learned modality embedding and temporal position embedding, the tokens from a series are fed into a transformer encoder together with a CLS token which is then used to predict the relative robot pose. Specifically, for 4D vision feature tokenizer, we took inspiration from bevodom and computed a correlation volume between two consecutive 3D voxel features. For IMU and wheel data, we use a small LSTM to encode raw data between two image frames into a single token. Training for the odometry head follows a straightforward supervised learning setup where the objective is to minimize the L1 loss between the predicted delta pose and ground truth pose."}),(0,Q.jsxs)("div",{className:"flex flex-row justify-between w-full",children:[(0,Q.jsx)(ae,{imgSrc:I,className:e?"mt-[20px] w-[30%]":"mt-[50px] w-[30%]",subtitle:"Figure 7a: Sequence 1"}),(0,Q.jsx)(ae,{imgSrc:q,className:e?"mt-[20px] w-[30%]":"mt-[50px] w-[30%]",subtitle:"Figure 7b: Sequence 2"}),(0,Q.jsx)(ae,{imgSrc:W,className:e?"mt-[20px] w-[30%]":"mt-[50px] w-[30%]",subtitle:"Figure 7c: Sequence 3"})]})]}),(0,Q.jsx)(oe,{title:"Citation",children:(0,Q.jsxs)("div",{className:"overflow-x-auto whitespace-nowrap rounded-2xl bg-[#FAFBFC] p-5 text-xs leading-5",children:[(0,Q.jsx)("div",{children:"@article{chen2025astramobility,"}),(0,Q.jsx)("div",{className:"indent-[2em]",children:"title={Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning},"}),(0,Q.jsx)("div",{className:"indent-[2em]",children:"author={Bytedance Seed}"}),(0,Q.jsx)("div",{className:"indent-[2em]",children:"journal={arXiv preprint arXiv:2506.06205},"}),(0,Q.jsx)("div",{className:"indent-[2em]",children:"year={2025}"}),(0,Q.jsx)("div",{children:"}"})]})})]})}}}]);